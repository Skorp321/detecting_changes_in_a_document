services:
  frontend:
    build: 
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - REACT_APP_API_URL=/api
    ports:
      - "3000:80"
    depends_on:
      - backend
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  streamlit:
    build:
      context: ./streamlit_app
      dockerfile: Dockerfile
    ports:
      - "8501:8501"
    depends_on:
      - backend
    environment:
      - API_BASE_URL=http://backend:8000
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - SECRET_KEY=your_secret_key_here_change_in_production
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-qwen3:32b}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://10f9698e-46b7-4a33-be37-f6495989f01f.modelrun.inference.cloud.ru}
      - ALLOWED_EXTENSIONS=pdf,docx,txt
      - CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000,http://95.31.20.57:3000,http://95.31.20.57,http://localhost,http://localhost:8501
      - MAX_FILE_SIZE=${MAX_FILE_SIZE:-52428800}
      - FORCE_REBUILD_FAISS=true
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

volumes:
  redis_data:
    driver: local

networks:
  app-network:
    driver: bridge
